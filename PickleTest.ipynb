{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['signal', 'label', 'subject'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the .pkl file for Subject 3 (S3.pkl)\n",
    "with open('S2//S2.pkl', 'rb') as file:\n",
    "    data = pickle.load(file, encoding='latin1')\n",
    "\n",
    "# Check the keys in the loaded dictionary\n",
    "print(data.keys())  # This will show the keys like 'signal', 'label', etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['signal', 'label', 'subject'])\n",
      "Chest data keys: dict_keys(['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'])\n",
      "Wrist data keys: dict_keys(['ACC', 'BVP', 'EDA', 'TEMP'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the .pkl file for Subject 3 (S3.pkl) with encoding\n",
    "with open('S2/S2.pkl', 'rb') as file:\n",
    "    data = pickle.load(file, encoding='latin1')\n",
    "\n",
    "# Check the available keys to see what's inside\n",
    "print(data.keys())  # Should show 'signal', 'label', etc.\n",
    "\n",
    "# Access sensor data\n",
    "chest_data = data['signal']['chest']  # Chest (RespiBAN) data\n",
    "wrist_data = data['signal']['wrist']  # Wrist (Empatica E4) data\n",
    "labels = data['label']  # Protocol condition labels\n",
    "\n",
    "# Check the keys of chest and wrist data dictionaries\n",
    "print('Chest data keys:', chest_data.keys())  # Check what sensors are available\n",
    "print('Wrist data keys:', wrist_data.keys())  # Check wrist sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chest EDA shape: 4255300\n",
      "First few values of Chest EDA: [[5.25054932]\n",
      " [5.26733398]\n",
      " [5.24330139]\n",
      " [5.24940491]\n",
      " [5.28640747]]\n",
      "Wrist EDA shape: 24316\n",
      "First few values of Wrist EDA: [[1.138257]\n",
      " [1.125444]\n",
      " [1.011405]\n",
      " [1.033188]\n",
      " [0.935807]]\n"
     ]
    }
   ],
   "source": [
    "# Access a specific sensor, for example, EDA (electrodermal activity) from chest and wrist\n",
    "chest_eda = chest_data['EDA']  # Replace 'EDA' with the correct key from the chest data keys\n",
    "wrist_eda = wrist_data['EDA']  # Replace 'EDA' with the correct key from the wrist data keys\n",
    "\n",
    "# Check the shape of the EDA data (you can print the length or first few rows)\n",
    "print('Chest EDA shape:', len(chest_eda))  # For a dictionary, we check length\n",
    "print('First few values of Chest EDA:', chest_eda[:5])\n",
    "\n",
    "print('Wrist EDA shape:', len(wrist_eda))\n",
    "print('First few values of Wrist EDA:', wrist_eda[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped data for S10\n",
      "Successfully processed and saved data for S10\n",
      "Unzipped data for S11\n",
      "Successfully processed and saved data for S11\n",
      "Unzipped data for S13\n",
      "Successfully processed and saved data for S13\n",
      "Unzipped data for S14\n",
      "Successfully processed and saved data for S14\n",
      "Unzipped data for S15\n",
      "Successfully processed and saved data for S15\n",
      "Unzipped data for S16\n",
      "Successfully processed and saved data for S16\n",
      "Unzipped data for S17\n",
      "Successfully processed and saved data for S17\n",
      "Unzipped data for S2\n",
      "Successfully processed and saved data for S2\n",
      "Unzipped data for S3\n",
      "Successfully processed and saved data for S3\n",
      "Unzipped data for S4\n",
      "Successfully processed and saved data for S4\n",
      "Unzipped data for S5\n",
      "Successfully processed and saved data for S5\n",
      "Unzipped data for S6\n",
      "Successfully processed and saved data for S6\n",
      "Unzipped data for S7\n",
      "Successfully processed and saved data for S7\n",
      "Unzipped data for S8\n",
      "Successfully processed and saved data for S8\n",
      "Unzipped data for S9\n",
      "Successfully processed and saved data for S9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Function to resample data\n",
    "def resample_data(df, original_freq, target_freq=4):\n",
    "    \"\"\"\n",
    "    Resample the dataframe based on the target frequency (4Hz by default).\n",
    "    original_freq: the original sampling rate of the data\n",
    "    target_freq: the new sampling rate (default: 4 Hz)\n",
    "    \"\"\"\n",
    "    factor = original_freq // target_freq\n",
    "    return df.iloc[::factor, :].reset_index(drop=True)\n",
    "\n",
    "# Define the base directory where subject folders are stored\n",
    "base_dir = 'BeforeProcessing'  # Change to your actual path\n",
    "output_dir = 'CorrectedFrequency'  # Directory to save processed data\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create output folder if it doesn't exist\n",
    "\n",
    "# List of subject folders (e.g., S2, S3, S4...)\n",
    "subject_folders = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
    "\n",
    "# Iterate through each subject folder\n",
    "for subject in subject_folders:\n",
    "    subject_path = os.path.join(base_dir, subject)\n",
    "    zip_file_path = os.path.join(subject_path, f'{subject}_E4_Data.zip')  # Path to the zipped data\n",
    "    extract_dir = os.path.join(subject_path, 'E4_Data')  # Directory to extract the zip content\n",
    "    output_path = os.path.join(output_dir, f'{subject}_processed.csv')\n",
    "\n",
    "    try:\n",
    "        # Unzip the Empatica E4 data\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "        print(f'Unzipped data for {subject}')\n",
    "\n",
    "        # Load wrist-worn data (ACC, BVP, EDA, TEMP) from the extracted folder\n",
    "        acc_file = os.path.join(extract_dir, 'ACC.csv')\n",
    "        bvp_file = os.path.join(extract_dir, 'BVP.csv')\n",
    "        eda_file = os.path.join(extract_dir, 'EDA.csv')\n",
    "        temp_file = os.path.join(extract_dir, 'TEMP.csv')\n",
    "        hr_file = os.path.join(extract_dir, 'HR.csv')  # Load HR from the correct file\n",
    "\n",
    "        # Load each sensor data (skip the first two lines as they contain metadata)\n",
    "        acc_data = pd.read_csv(acc_file, skiprows=2, header=None, names=['ACC_X', 'ACC_Y', 'ACC_Z'])\n",
    "        bvp_data = pd.read_csv(bvp_file, skiprows=2, header=None, names=['BVP'])\n",
    "        eda_data = pd.read_csv(eda_file, skiprows=2, header=None, names=['EDA'])\n",
    "        temp_data = pd.read_csv(temp_file, skiprows=2, header=None, names=['TEMP'])\n",
    "        hr_data = pd.read_csv(hr_file, skiprows=2, header=None, names=['HR'])  # Correctly load HR data\n",
    "\n",
    "        # Resample ACC (32 Hz to 4 Hz) and BVP (64 Hz to 4 Hz)\n",
    "        acc_resampled = resample_data(acc_data, original_freq=32)\n",
    "        bvp_resampled = resample_data(bvp_data, original_freq=64)\n",
    "\n",
    "        # HR data is generally at 1 Hz, resampling it is not necessary, but if needed, you could:\n",
    "        # hr_resampled = resample_data(hr_data, original_freq=1)  # Uncomment if needed\n",
    "\n",
    "        # EDA and TEMP are already at 4 Hz, so we can use them directly\n",
    "        # Concatenate all data into a single dataframe\n",
    "        processed_data = pd.concat([acc_resampled, bvp_resampled, eda_data, temp_data, hr_data], axis=1)\n",
    "\n",
    "        # Save the processed data to a new CSV file\n",
    "        processed_data.to_csv(output_path, index=False)\n",
    "        print(f'Successfully processed and saved data for {subject}')\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(f\"File not found for {subject}: {fnf_error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {subject}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing subject S2...\n",
      "Loaded sensor data for S2, shape: (31497, 8)\n",
      "Sensor Score: 1.33, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50, Overall Score: 1.27\n",
      "\n",
      "Processed Base for S2:\n",
      "Time window: 7.08 - 26.32\n",
      "Label: Neutral\n",
      "Sensor averages - HR: 74.15, TEMP: 34.93, EDA: 0.59\n",
      "Sensor score: 1.33\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50\n",
      "Overall score: 1.27\n",
      "\n",
      "Successfully labeled data for S2\n",
      "Label distribution:\n",
      "Label\n",
      "Neutral    31497\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S3...\n",
      "Loaded sensor data for S3, shape: (30895, 8)\n",
      "Sensor Score: 0.33, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 2.50, Overall Score: 0.65\n",
      "\n",
      "Processed Base for S3:\n",
      "Time window: 6.44 - 26.04\n",
      "Label: Calm\n",
      "Sensor averages - HR: 69.20, TEMP: 32.57, EDA: 1.93\n",
      "Sensor score: 0.33\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 2.50\n",
      "Overall score: 0.65\n",
      "\n",
      "Successfully labeled data for S3\n",
      "Label distribution:\n",
      "Label\n",
      "Neutral    17174\n",
      "Calm       13721\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S4...\n",
      "Loaded sensor data for S4, shape: (31998, 8)\n",
      "Sensor Score: -0.33, Stress: 2.00, Frustration: 2.00, Anxiety: 1.00, Arousal: 1.50, Overall Score: 0.25\n",
      "\n",
      "Processed Base for S4:\n",
      "Time window: 5.52 - 25.3\n",
      "Label: Calm\n",
      "Sensor averages - HR: 68.15, TEMP: 32.80, EDA: 0.17\n",
      "Sensor score: -0.33\n",
      "Questionnaire scores - Stress: 2.00, Frustration: 2.00, Anxiety: 1.00, Arousal: 1.50\n",
      "Overall score: 0.25\n",
      "Sensor Score: 1.33, Stress: 1.00, Frustration: 2.00, Anxiety: 1.00, Arousal: 4.00, Overall Score: 1.53\n",
      "\n",
      "Processed Fun for S4:\n",
      "Time window: 31.39 - 38.11\n",
      "Label: Pre-Meltdown\n",
      "Sensor averages - HR: nan, TEMP: 32.08, EDA: 1.00\n",
      "Sensor score: 1.33\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 2.00, Anxiety: 1.00, Arousal: 4.00\n",
      "Overall score: 1.53\n",
      "\n",
      "Successfully labeled data for S4\n",
      "Label distribution:\n",
      "Label\n",
      "Calm            13848\n",
      "Neutral         13445\n",
      "Pre-Meltdown     4705\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S5...\n",
      "Loaded sensor data for S5, shape: (30204, 8)\n",
      "Sensor Score: 2.00, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50, Overall Score: 1.74\n",
      "\n",
      "Processed Base for S5:\n",
      "Time window: 5.37 - 25.55\n",
      "Label: Pre-Meltdown\n",
      "Sensor averages - HR: 81.59, TEMP: 34.57, EDA: 1.18\n",
      "Sensor score: 2.00\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50\n",
      "Overall score: 1.74\n",
      "Sensor Score: 1.33, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.00, Overall Score: 1.23\n",
      "\n",
      "Processed Fun for S5:\n",
      "Time window: 32.0 - 38.34\n",
      "Label: Neutral\n",
      "Sensor averages - HR: nan, TEMP: 31.82, EDA: 1.65\n",
      "Sensor score: 1.33\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.00\n",
      "Overall score: 1.23\n",
      "\n",
      "Successfully labeled data for S5\n",
      "Label distribution:\n",
      "Label\n",
      "Neutral         16077\n",
      "Pre-Meltdown    14127\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S6...\n",
      "Loaded sensor data for S6, shape: (33295, 8)\n",
      "Sensor Score: 0.50, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50, Overall Score: 0.69\n",
      "\n",
      "Processed Base for S6:\n",
      "Time window: 11.17 - 31.17\n",
      "Label: Calm\n",
      "Sensor averages - HR: 73.64, TEMP: 32.72, EDA: 3.94\n",
      "Sensor score: 0.50\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50\n",
      "Overall score: 0.69\n",
      "\n",
      "Successfully labeled data for S6\n",
      "Label distribution:\n",
      "Label\n",
      "Neutral    19294\n",
      "Calm       14001\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S7...\n",
      "Loaded sensor data for S7, shape: (25978, 8)\n",
      "Sensor Score: 0.33, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50, Overall Score: 0.57\n",
      "\n",
      "Processed Base for S7:\n",
      "Time window: 2.14 - 22.2\n",
      "Label: Calm\n",
      "Sensor averages - HR: 69.37, TEMP: 33.54, EDA: 5.04\n",
      "Sensor score: 0.33\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50\n",
      "Overall score: 0.57\n",
      "Sensor Score: 1.33, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50, Overall Score: 1.27\n",
      "\n",
      "Processed Fun for S7:\n",
      "Time window: 26.24 - 32.56\n",
      "Label: Neutral\n",
      "Sensor averages - HR: nan, TEMP: 32.40, EDA: 6.72\n",
      "Sensor score: 1.33\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50\n",
      "Overall score: 1.27\n",
      "\n",
      "Successfully labeled data for S7\n",
      "Label distribution:\n",
      "Label\n",
      "Calm       14043\n",
      "Neutral    11935\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S8...\n",
      "Loaded sensor data for S8, shape: (26554, 8)\n",
      "Sensor Score: 0.50, Stress: 2.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 2.00, Overall Score: 0.90\n",
      "\n",
      "Processed Base for S8:\n",
      "Time window: 3.56 - 23.45\n",
      "Label: Calm\n",
      "Sensor averages - HR: 73.41, TEMP: 33.40, EDA: 0.45\n",
      "Sensor score: 0.50\n",
      "Questionnaire scores - Stress: 2.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 2.00\n",
      "Overall score: 0.90\n",
      "Sensor Score: 1.33, Stress: 2.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 1.50, Overall Score: 1.45\n",
      "\n",
      "Processed Fun for S8:\n",
      "Time window: 29.0 - 35.3\n",
      "Label: Neutral\n",
      "Sensor averages - HR: nan, TEMP: 32.16, EDA: 0.47\n",
      "Sensor score: 1.33\n",
      "Questionnaire scores - Stress: 2.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 1.50\n",
      "Overall score: 1.45\n",
      "\n",
      "Successfully labeled data for S8\n",
      "Label distribution:\n",
      "Label\n",
      "Calm       13924\n",
      "Neutral    12630\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S9...\n",
      "Loaded sensor data for S9, shape: (24915, 8)\n",
      "Sensor Score: 1.17, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 2.00, Overall Score: 1.19\n",
      "\n",
      "Processed Base for S9:\n",
      "Time window: 1.48 - 21.48\n",
      "Label: Neutral\n",
      "Sensor averages - HR: 77.59, TEMP: 33.62, EDA: 0.58\n",
      "Sensor score: 1.17\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 2.00\n",
      "Overall score: 1.19\n",
      "\n",
      "Successfully labeled data for S9\n",
      "Label distribution:\n",
      "Label\n",
      "Neutral    24915\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S10...\n",
      "Loaded sensor data for S10, shape: (27291, 8)\n",
      "Sensor Score: 1.17, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50, Overall Score: 1.15\n",
      "\n",
      "Processed Base for S10:\n",
      "Time window: 2.5 - 22.5\n",
      "Label: Neutral\n",
      "Sensor averages - HR: 88.65, TEMP: 33.52, EDA: 0.39\n",
      "Sensor score: 1.17\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50\n",
      "Overall score: 1.15\n",
      "Sensor Score: 0.50, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.00, Overall Score: 0.65\n",
      "\n",
      "Processed Fun for S10:\n",
      "Time window: 27.53 - 34.25\n",
      "Label: Neutral\n",
      "Sensor averages - HR: nan, TEMP: 32.84, EDA: 1.63\n",
      "Sensor score: 0.50\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.00\n",
      "Overall score: 0.65\n",
      "\n",
      "Successfully labeled data for S10\n",
      "Label distribution:\n",
      "Label\n",
      "Neutral    27291\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S11...\n",
      "Loaded sensor data for S11, shape: (25842, 8)\n",
      "Sensor Score: 1.17, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50, Overall Score: 1.15\n",
      "\n",
      "Processed Base for S11:\n",
      "Time window: 2.23 - 22.23\n",
      "Label: Neutral\n",
      "Sensor averages - HR: 81.66, TEMP: 33.72, EDA: 4.11\n",
      "Sensor score: 1.17\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50\n",
      "Overall score: 1.15\n",
      "\n",
      "Successfully labeled data for S11\n",
      "Label distribution:\n",
      "Label\n",
      "Neutral    25842\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S13...\n",
      "Loaded sensor data for S13, shape: (27451, 8)\n",
      "Sensor Score: 2.00, Stress: 1.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 2.00, Overall Score: 1.88\n",
      "\n",
      "Processed Base for S13:\n",
      "Time window: 2.28 - 22.28\n",
      "Label: Meltdown\n",
      "Sensor averages - HR: 82.99, TEMP: 34.74, EDA: 6.35\n",
      "Sensor score: 2.00\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 2.00\n",
      "Overall score: 1.88\n",
      "Sensor Score: 0.50, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.00, Overall Score: 0.65\n",
      "\n",
      "Processed Fun for S13:\n",
      "Time window: 28.44 - 35.26\n",
      "Label: Neutral\n",
      "Sensor averages - HR: nan, TEMP: 33.28, EDA: 10.07\n",
      "Sensor score: 0.50\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.00\n",
      "Overall score: 0.65\n",
      "\n",
      "Successfully labeled data for S13\n",
      "Label distribution:\n",
      "Label\n",
      "Meltdown    14002\n",
      "Neutral     13449\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S14...\n",
      "Loaded sensor data for S14, shape: (27946, 8)\n",
      "Sensor Score: 2.00, Stress: 1.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 1.50, Overall Score: 1.84\n",
      "\n",
      "Processed Base for S14:\n",
      "Time window: 2.0 - 22.0\n",
      "Label: Meltdown\n",
      "Sensor averages - HR: 85.53, TEMP: 32.26, EDA: 0.33\n",
      "Sensor score: 2.00\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 1.50\n",
      "Overall score: 1.84\n",
      "\n",
      "Successfully labeled data for S14\n",
      "Label distribution:\n",
      "Label\n",
      "Meltdown    14001\n",
      "Neutral     13945\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S15...\n",
      "Loaded sensor data for S15, shape: (26572, 8)\n",
      "Sensor Score: 2.00, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 3.00, Overall Score: 1.85\n",
      "\n",
      "Processed Base for S15:\n",
      "Time window: 4.25 - 24.2\n",
      "Label: Pre-Meltdown\n",
      "Sensor averages - HR: 78.51, TEMP: 30.05, EDA: 0.36\n",
      "Sensor score: 2.00\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 3.00\n",
      "Overall score: 1.85\n",
      "Sensor Score: 1.33, Stress: 1.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 1.50, Overall Score: 1.37\n",
      "\n",
      "Processed Fun for S15:\n",
      "Time window: 29.26 - 35.58\n",
      "Label: Neutral\n",
      "Sensor averages - HR: nan, TEMP: 29.87, EDA: 0.87\n",
      "Sensor score: 1.33\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 1.50\n",
      "Overall score: 1.37\n",
      "\n",
      "Successfully labeled data for S15\n",
      "Label distribution:\n",
      "Label\n",
      "Pre-Meltdown    13966\n",
      "Neutral         12606\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S16...\n",
      "Loaded sensor data for S16, shape: (28429, 8)\n",
      "Sensor Score: 2.00, Stress: 1.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 1.50, Overall Score: 1.84\n",
      "\n",
      "Processed Base for S16:\n",
      "Time window: 3.0 - 23.0\n",
      "Label: Meltdown\n",
      "Sensor averages - HR: 83.02, TEMP: 30.15, EDA: 0.69\n",
      "Sensor score: 2.00\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 1.50\n",
      "Overall score: 1.84\n",
      "\n",
      "Successfully labeled data for S16\n",
      "Label distribution:\n",
      "Label\n",
      "Neutral     14428\n",
      "Meltdown    14001\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing subject S17...\n",
      "Loaded sensor data for S17, shape: (28927, 8)\n",
      "Sensor Score: 1.17, Stress: 1.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 1.50, Overall Score: 1.25\n",
      "\n",
      "Processed Base for S17:\n",
      "Time window: 3.02 - 23.03\n",
      "Label: Neutral\n",
      "Sensor averages - HR: 75.36, TEMP: 33.20, EDA: 1.77\n",
      "Sensor score: 1.17\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 2.33, Arousal: 1.50\n",
      "Overall score: 1.25\n",
      "Sensor Score: 0.50, Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50, Overall Score: 0.69\n",
      "\n",
      "Processed Fun for S17:\n",
      "Time window: 30.3 - 37.02\n",
      "Label: Neutral\n",
      "Sensor averages - HR: nan, TEMP: 32.59, EDA: 0.98\n",
      "Sensor score: 0.50\n",
      "Questionnaire scores - Stress: 1.00, Frustration: 1.00, Anxiety: 1.00, Arousal: 1.50\n",
      "Overall score: 0.69\n",
      "\n",
      "Successfully labeled data for S17\n",
      "Label distribution:\n",
      "Label\n",
      "Neutral    28927\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate score based on sensor values, without considering BVP\n",
    "def map_labels(sensor_score, stress, frustration, anxiety, arousal, condition):\n",
    "    \"\"\"Map sensor scores and questionnaire data to labels with a more balanced distribution.\"\"\"\n",
    "    # Combine sensor score and psychological questionnaire data\n",
    "    overall_score = (sensor_score * 0.7) + ((stress + frustration + anxiety + arousal) / 4 * 0.3)\n",
    "\n",
    "    # Debugging output\n",
    "    print(f\"Sensor Score: {sensor_score:.2f}, Stress: {stress:.2f}, Frustration: {frustration:.2f}, \"\n",
    "          f\"Anxiety: {anxiety:.2f}, Arousal: {arousal:.2f}, Overall Score: {overall_score:.2f}\")\n",
    "\n",
    "    # Adjust thresholds for more balanced distribution\n",
    "    if overall_score > 2.5 or (sensor_score >= 2.0 and (stress > 2.0 or frustration > 2.0 or anxiety > 2.0)):\n",
    "        return \"Meltdown\"\n",
    "    elif 1.5 < overall_score <= 2.5 or (sensor_score >= 1.5 and (stress > 1.5 or frustration > 1.5 or anxiety > 1.5)):\n",
    "        return \"Pre-Meltdown\"\n",
    "    elif overall_score <= 1.0 and condition == \"Base\":\n",
    "        return \"Calm\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Helper function to normalize questionnaire scores\n",
    "def normalize_score(score, min_val, max_val):\n",
    "    return (score - min_val) / (max_val - min_val) * 4 + 1  # Scale to 1-5 range\n",
    "\n",
    "# Updated calculate_sensor_score function\n",
    "def calculate_sensor_score(hr, temp, eda):\n",
    "    score = 0\n",
    "    # HR: Stress if HR > 75 bpm, calm if between 60-70 bpm\n",
    "    if hr > 75:\n",
    "        score += 2\n",
    "    elif 60 <= hr <= 70:\n",
    "        score -= 0.5\n",
    "\n",
    "    # TEMP: Stress if outside 32.5°C - 34.5°C range\n",
    "    if temp < 32.5 or temp > 34.5:\n",
    "        score += 2\n",
    "    else:\n",
    "        score -= 0.5\n",
    "\n",
    "    # EDA: Stress if above 0.3, calm if below 0.1\n",
    "    if eda > 0.3:\n",
    "        score += 2\n",
    "    elif eda < 0.1:\n",
    "        score -= 0.5\n",
    "\n",
    "    return score / 3  # Normalize to 0-2 range\n",
    "\n",
    "# Load the SX_quest.csv file for each subject\n",
    "def process_questionnaire_and_label(quest_folder, subject_id, sensor_data):\n",
    "    quest_file = os.path.join(quest_folder, f'{subject_id}', f'{subject_id}_quest.csv')\n",
    "    \n",
    "    try:\n",
    "        # Read the questionnaire file\n",
    "        with open(quest_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Parse the protocol order\n",
    "        order_line = [line for line in lines if '# ORDER' in line][0]\n",
    "        conditions = [cond.strip() for cond in order_line.split(';')[1:] if cond.strip()]\n",
    "\n",
    "        # Parse times\n",
    "        start_line = [line for line in lines if '# START' in line][0]\n",
    "        end_line = [line for line in lines if '# END' in line][0]\n",
    "        \n",
    "        start_times = [float(t) for t in start_line.split(';')[1:] if t.strip()]\n",
    "        end_times = [float(t) for t in end_line.split(';')[1:] if t.strip()]\n",
    "        \n",
    "        # Extract questionnaire data\n",
    "        panas_lines = [line for line in lines if '# PANAS' in line]\n",
    "        stai_lines = [line for line in lines if '# STAI' in line]\n",
    "        dim_lines = [line for line in lines if '# DIM' in line]\n",
    "        \n",
    "        # Process only the main conditions (baseline, stress, amusement, meditation)\n",
    "        valid_conditions = ['Base', 'TSST', 'Fun', 'Medi 1', 'Medi 2']\n",
    "        \n",
    "        labels = []\n",
    "        valid_start_times = []\n",
    "        valid_end_times = []\n",
    "        \n",
    "        for i, condition in enumerate(conditions):\n",
    "            if condition in valid_conditions and i < len(start_times):\n",
    "                try:\n",
    "                    # Find corresponding questionnaire responses\n",
    "                    condition_idx = valid_conditions.index(condition)\n",
    "                    \n",
    "                    # Get PANAS scores for this condition\n",
    "                    panas_scores = [float(x) for x in panas_lines[condition_idx].split(';')[1:] if x.strip()]\n",
    "                    \n",
    "                    # Get STAI scores for this condition\n",
    "                    stai_scores = [float(x) for x in stai_lines[condition_idx].split(';')[1:] if x.strip()]\n",
    "                    \n",
    "                    # Get DIM (SAM) scores for this condition\n",
    "                    dim_scores = [float(x) for x in dim_lines[condition_idx].split(';')[1:] if x.strip()]\n",
    "                    \n",
    "                    # Calculate sensor scores for this time window (excluding BVP)\n",
    "                    start_sample = int(start_times[i] * 700)  # Convert to samples (700 Hz)\n",
    "                    end_sample = int(end_times[i] * 700)\n",
    "                    \n",
    "                    if start_sample < len(sensor_data) and end_sample <= len(sensor_data):\n",
    "                        sensor_window = sensor_data.iloc[start_sample:end_sample]\n",
    "                        \n",
    "                        avg_hr = sensor_window['HR'].mean()\n",
    "                        avg_temp = sensor_window['TEMP'].mean()\n",
    "                        avg_eda = sensor_window['EDA'].mean()\n",
    "                        \n",
    "                        stress = normalize_score(float(panas_scores[1]), 1, 5)  # Distressed (stress)\n",
    "                        frustration = normalize_score(float(panas_scores[4]), 1, 5)  # Annoyed (frustration)\n",
    "                        anxiety = normalize_score(float(stai_scores[2]), 1, 4)  # \"I am jittery\" from STAI\n",
    "                        arousal = normalize_score(float(dim_scores[1]), 1, 9)  # Arousal from SAM\n",
    "\n",
    "                        sensor_score = calculate_sensor_score(avg_hr, avg_temp, avg_eda)\n",
    "                        \n",
    "                        # Generate label\n",
    "                        label = map_labels(\n",
    "                            sensor_score,\n",
    "                            stress,\n",
    "                            frustration,\n",
    "                            anxiety,\n",
    "                            arousal,\n",
    "                            condition\n",
    "                        )\n",
    "                        \n",
    "                        labels.append(label)\n",
    "                        valid_start_times.append(start_times[i])\n",
    "                        valid_end_times.append(end_times[i])\n",
    "                        \n",
    "                        print(f\"\\nProcessed {condition} for {subject_id}:\")\n",
    "                        print(f\"Time window: {start_times[i]} - {end_times[i]}\")\n",
    "                        print(f\"Label: {label}\")\n",
    "                        print(f\"Sensor averages - HR: {avg_hr:.2f}, TEMP: {avg_temp:.2f}, EDA: {avg_eda:.2f}\")\n",
    "                        print(f\"Sensor score: {sensor_score:.2f}\")\n",
    "                        print(f\"Questionnaire scores - Stress: {stress:.2f}, Frustration: {frustration:.2f}, Anxiety: {anxiety:.2f}, Arousal: {arousal:.2f}\")\n",
    "                        print(f\"Overall score: {(sensor_score * 0.7) + ((stress + frustration + anxiety + arousal) / 4 * 0.3):.2f}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing condition {condition} for {subject_id}: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        return labels, valid_start_times, valid_end_times\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing questionnaire for {subject_id}:\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return [], [], []\n",
    "\n",
    "def label_and_merge_sensor_data(processed_folder, subject_id, labels, start_times, end_times):\n",
    "    try:\n",
    "        processed_file = os.path.join(processed_folder, f'{subject_id}_processed.csv')\n",
    "        sensor_data = pd.read_csv(processed_file)\n",
    "        \n",
    "        # Initialize all labels as Neutral\n",
    "        sensor_data['Label'] = \"Neutral\"\n",
    "        \n",
    "        # Apply labels for valid time windows\n",
    "        for label, start, end in zip(labels, start_times, end_times):\n",
    "            start_idx = min(int(start * 700), len(sensor_data) - 1)\n",
    "            end_idx = min(int(end * 700), len(sensor_data) - 1)\n",
    "            sensor_data.loc[start_idx:end_idx, 'Label'] = label\n",
    "            \n",
    "        sensor_data.to_csv(processed_file, index=False)\n",
    "        print(f\"\\nSuccessfully labeled data for {subject_id}\")\n",
    "        print(f\"Label distribution:\")\n",
    "        print(sensor_data['Label'].value_counts())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving labeled data for {subject_id}: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    quest_folder = 'BeforeProcessing'\n",
    "    processed_folder = 'CorrectedFrequency'\n",
    "    subjects = [f'S{i}' for i in range(2, 18) if i != 1 and i != 12]\n",
    "    \n",
    "    for subject_id in subjects:\n",
    "        print(f\"\\nProcessing subject {subject_id}...\")\n",
    "        \n",
    "        try:\n",
    "            sensor_file = os.path.join(processed_folder, f'{subject_id}_processed.csv')\n",
    "            \n",
    "            if not os.path.exists(sensor_file):\n",
    "                print(f\"Sensor data file not found for {subject_id}\")\n",
    "                continue\n",
    "                \n",
    "            sensor_data = pd.read_csv(sensor_file)\n",
    "            print(f\"Loaded sensor data for {subject_id}, shape: {sensor_data.shape}\")\n",
    "            \n",
    "            labels, start_times, end_times = process_questionnaire_and_label(quest_folder, subject_id, sensor_data)\n",
    "            \n",
    "            if labels:\n",
    "                label_and_merge_sensor_data(processed_folder, subject_id, labels, start_times, end_times)\n",
    "            else:\n",
    "                print(f\"No valid labels generated for {subject_id}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {subject_id}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Label Counts:\n",
      "Neutral: 283455\n",
      "Meltdown: 42004\n",
      "Pre-Meltdown: 32798\n",
      "Calm: 69537\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_labels_in_folder(processed_folder):\n",
    "    label_counter = defaultdict(int)  # Use a defaultdict to automatically initialize counts to zero\n",
    "\n",
    "    # Iterate through each file in the specified folder\n",
    "    for filename in os.listdir(processed_folder):\n",
    "        if filename.endswith('.csv'):  # Check for CSV files\n",
    "            file_path = os.path.join(processed_folder, filename)\n",
    "            \n",
    "            try:\n",
    "                # Load the sensor data file\n",
    "                sensor_data = pd.read_csv(file_path)\n",
    "                \n",
    "                # Count occurrences of each label\n",
    "                for label in sensor_data['Label'].dropna().unique():  # Using dropna() to ignore any NaN labels\n",
    "                    label_counter[label] += sensor_data['Label'].value_counts().get(label, 0)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {str(e)}\")\n",
    "    \n",
    "    return label_counter\n",
    "\n",
    "def main():\n",
    "    processed_folder = 'CorrectedFrequency'  # Adjust the folder path as needed\n",
    "    label_counts = count_labels_in_folder(processed_folder)\n",
    "\n",
    "    # Print the final counts for each label\n",
    "    print(\"Final Label Counts:\")\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"{label}: {count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ACC_X  ACC_Y  ACC_Z     BVP       EDA    TEMP     HR    Label SubjectID  \\\n",
      "0    5.0    1.0   63.0   -0.00  0.000000  382.21  71.00  Neutral       S10   \n",
      "1    5.0    1.0   63.0   -0.05  0.226414  382.21  71.00  Neutral       S10   \n",
      "2    5.0    1.0   63.0    6.20  0.287814  382.21  70.67  Neutral       S10   \n",
      "3    6.0    1.0   63.0   22.90  0.294210  382.21  71.25  Neutral       S10   \n",
      "4    5.0    1.0   63.0   93.76  0.295489   31.19  72.20  Neutral       S10   \n",
      "5    5.0    1.0   63.0  208.53  0.294210   31.19  73.50  Neutral       S10   \n",
      "6    5.0    1.0   63.0 -537.23  0.296768   31.19  74.57  Neutral       S10   \n",
      "7    6.0    1.0   63.0   71.43  0.295489   31.19  75.50  Neutral       S10   \n",
      "8    5.0    1.0   63.0  141.30  0.291652   31.19  76.33  Neutral       S10   \n",
      "9    5.0    1.0   63.0   37.59  0.294210   31.19  76.80  Neutral       S10   \n",
      "\n",
      "   Time  \n",
      "0     0  \n",
      "1     1  \n",
      "2     2  \n",
      "3     3  \n",
      "4     4  \n",
      "5     5  \n",
      "6     6  \n",
      "7     7  \n",
      "8     8  \n",
      "9     9  \n",
      "Data merged and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to merge data from multiple subjects\n",
    "def merge_subject_data(folder_path):\n",
    "    merged_data = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through all CSV files in the specified folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('_processed.csv'):  # Ensure we only process the correct files\n",
    "            subject_file = os.path.join(folder_path, filename)\n",
    "            # Load subject data\n",
    "            subject_data = pd.read_csv(subject_file)\n",
    "            \n",
    "            # Extract subject ID from filename\n",
    "            subject_id = filename.split('_')[0]\n",
    "            subject_data['SubjectID'] = subject_id  # Add SubjectID column\n",
    "            \n",
    "            # Create a new time column starting from 0\n",
    "            subject_data['Time'] = range(len(subject_data))  # Add a sequential time column\n",
    "            \n",
    "            # Merge subject data into the combined dataframe\n",
    "            merged_data = pd.concat([merged_data, subject_data], ignore_index=True)\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'CorrectedFrequency'  # Path to the folder containing subject files\n",
    "merged_data = merge_subject_data(folder_path)\n",
    "\n",
    "# Show a sample of the merged data\n",
    "print(merged_data.head(10))  # Display first 10 rows of the merged data\n",
    "\n",
    "# Save merged data to a CSV file\n",
    "merged_data.to_csv('merged_subject_data.csv', index=False)\n",
    "print(\"Data merged and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
